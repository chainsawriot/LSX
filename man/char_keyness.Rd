% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel.R
\name{char_keyness}
\alias{char_keyness}
\title{Identify keywords occur frequently with target words}
\usage{
char_keyness(x, pattern, valuetype = c("glob", "regex", "fixed"),
  case_insensitive = TRUE, window = 10, p = 0.001, min_count = 10,
  remove_pattern = TRUE, ...)
}
\arguments{
\item{x}{tokens object created by \code{\link[quanteda]{tokens}}.}

\item{pattern}{to specify target words. See \code{\link[quanteda]{pattern}} for details.}

\item{valuetype}{the type of pattern matching: \code{"glob"} for
"glob"-style wildcard expressions; \code{"regex"} for regular expressions;
or \code{"fixed"} for exact matching. See \code{\link[quanteda]{valuetype}} for details.}

\item{case_insensitive}{ignore case when matching, if \code{TRUE}}

\item{window}{size of window for collocation analysis.}

\item{p}{threashold for statistical significance of collocaitons.}

\item{min_count}{minimum frequency for words within the window to be
considered as collocations.}

\item{remove_pattern}{if \code{TRUE}, keywords do not containe target words.}

\item{...}{additional arguments passed to \code{\link{textstat_keyness}}.}
}
\description{
Identify keywords occur frequently with target words
}
\examples{
require(quanteda)
load('/home/kohei/Dropbox/Public/guardian-sample.RData')
corp <- corpus_reshape(data_corpus_guardian, 'sentences')
toks <- tokens(corp, remove_punct = TRUE)
toks <- tokens_remove(toks, stopwords())

# economy keywords
eco <- char_keyness(toks, 'econom*')
head(eco, 20)

# politics keywords
pol <- char_keyness(toks, 'politi*')
head(pol, 20)
}
\seealso{
\code{\link{tokens_select}} and \code{\link{textstat_keyness}}
}
